{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNGy3oJaoF55"
      },
      "source": [
        "This notebook provides code to train model on the airbus dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmAHuwrusR1E",
        "outputId": "81a10bbd-8996-4a0f-c911-81f8ea6b7766"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "# This mounts your Google Drive to the Colab VM.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "\n",
        "# Enter the foldername in your Drive where you have saved the unzipped\n",
        "# assignment folder, e.g. 'cs231n/assignments/assignment1/'\n",
        "FOLDERNAME = 'test_archi_IA'\n",
        "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
        "\n",
        "# Now that we've mounted your Drive, this ensures that\n",
        "# the Python interpreter of the Colab VM can load\n",
        "# python files from within it.\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NidNh7616Wes"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0CZGRgJsq_N"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "from time import time\n",
        "import math\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D, DepthwiseConv2D, ReLU, BatchNormalization, add,Softmax, AveragePooling2D, Dense, Input, GlobalAveragePooling2D,Add\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9Rq9_odsuaM",
        "outputId": "3d057512-60b2-4311-8ad6-9b54072abb9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/transfer_learning_mobilenet/dataset_airbus/dataset_airbus\n",
            "/content/drive/MyDrive/test_archi_IA/part_of_dataset_airbus_test\n"
          ]
        }
      ],
      "source": [
        "#extraction de la dataset\n",
        "import pathlib\n",
        "import os\n",
        "import zipfile\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# training_dataset_file_name = \"./drive/MyDrive/transfer_learning_mobilenet/dataset_airbus_240.zip\"\n",
        "# with ZipFile(training_dataset_file_name, 'r') as zip:\n",
        "#       zip.extractall('./drive/MyDrive/transfer_learning_mobilenet/')\n",
        "\n",
        "data_dir_train = pathlib.Path('./drive/MyDrive/transfer_learning_mobilenet/dataset_airbus/dataset_airbus') # airbus\n",
        "print(os.path.abspath(data_dir_train))\n",
        "data_dir_test = pathlib.Path('./drive/MyDrive/test_archi_IA/part_of_dataset_airbus_test')\n",
        "print(os.path.abspath(data_dir_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8_tFabIozhr"
      },
      "source": [
        "Import training dataset (airbus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7p5cQkBjsw6k",
        "outputId": "65bfbc66-24af-40f6-b91c-1acb097491c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 75069 files belonging to 2 classes.\n",
            "Using 60056 files for training.\n",
            "['bateau', 'pas_bateau']\n",
            "Found 75069 files belonging to 2 classes.\n",
            "Using 15013 files for validation.\n",
            "['bateau', 'pas_bateau']\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "list_train = os.listdir('./drive/MyDrive/transfer_learning_mobilenet/dataset_airbus/dataset_airbus')#airbus\n",
        "\n",
        "\n",
        "n_classes = 2\n",
        "image_height = 240\n",
        "image_width = 240\n",
        "n_channel = 3\n",
        "batch_size = 20\n",
        "\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    directory=data_dir_train,\n",
        "    subset = 'training',\n",
        "    shuffle = True,\n",
        "    validation_split = 0.2,\n",
        "    seed=42,\n",
        "    batch_size=batch_size,\n",
        "    image_size=(image_height,image_width))\n",
        "\n",
        "class_names_train = list_train\n",
        "print(class_names_train)\n",
        "\n",
        "\n",
        "validation_dataset = image_dataset_from_directory(\n",
        "    directory=data_dir_train,\n",
        "    subset = 'validation',\n",
        "    shuffle = True,\n",
        "    validation_split = 0.2,\n",
        "    seed=42,\n",
        "    batch_size=batch_size,\n",
        "    image_size=(image_height,image_width))\n",
        "\n",
        "class_names = validation_dataset.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRWhheP1pJLa"
      },
      "source": [
        "Import your test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b42h3UvMs1I8",
        "outputId": "8e45237f-b688-4e1a-afb4-f9ab405b0720"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 121 files belonging to 2 classes.\n",
            "['bateau', 'pas_bateau']\n"
          ]
        }
      ],
      "source": [
        "\"\"\"test_file_name = \"./drive/MyDrive/code_laetitia/test_dataset.zip\"\n",
        "with ZipFile(test_file_name, 'r') as zip:\n",
        "    zip.extractall('./drive/MyDrive/code_laetitia/')\"\"\"\n",
        "\n",
        "list_test = os.listdir('./drive/MyDrive/test_archi_IA/part_of_dataset_airbus_test')\n",
        "test_dataset = image_dataset_from_directory(\n",
        "    directory=data_dir_test,\n",
        "    seed=42,\n",
        "    batch_size=batch_size,\n",
        "    image_size=(image_height,image_width))\n",
        "\n",
        "class_names_test = list_test\n",
        "print(class_names_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGIPKH9n6sHu"
      },
      "source": [
        "Dataset augmention for improved training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vOEq3DFs52s"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.RandomFlip('horizontal'),\n",
        "  tf.keras.layers.RandomRotation(0.2),\n",
        "])\n",
        "\n",
        "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
        "rescale = tf.keras.layers.Rescaling(1./127.5, offset=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_44F0W1DpYBX"
      },
      "source": [
        "Prepare your model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JyFkpBHcJQj",
        "outputId": "706d9e18-998e-4fde-be87-fb48a5645dd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 240, 240, 3)]     0         \n",
            "                                                                 \n",
            " rescaling (Rescaling)       (None, 240, 240, 3)       0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 240, 240, 8)       224       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 120, 120, 8)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 120, 120, 16)      1168      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 60, 60, 16)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 60, 60, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 30, 30, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 30, 30, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 15, 15, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 7200)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                230432    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 245,778\n",
            "Trainable params: 245,778\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "conv2D = tf.keras.layers.Conv2D(64, (3,3), activation = 'relu')\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "\n",
        "\n",
        "inputs = tf.keras.Input(shape=(240, 240, 3))\n",
        "network = rescale(inputs)\n",
        "\n",
        "network = tf.keras.layers.Conv2D(8, (3,3), padding='same', activation='relu')(network)\n",
        "network = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(network)\n",
        "\n",
        "network = tf.keras.layers.Conv2D(16, (3,3), padding='same', activation='relu')(network) \n",
        "network = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(network)\n",
        "\n",
        "network = tf.keras.layers.Conv2D(32, (3,3), padding='same', activation='relu')(network)\n",
        "network = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(network)\n",
        "\n",
        "network = tf.keras.layers.Conv2D(32, (3,3), padding='same', activation='relu')(network)\n",
        "network = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(network)\n",
        "\n",
        "network = tf.keras.layers.Flatten()(network)\n",
        "network = tf.keras.layers.Dense(32, activation='relu')(network)\n",
        "outputs = tf.keras.layers.Dense(2, activation = 'softmax')(network)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUwYYtWqpbau"
      },
      "source": [
        "Weights table shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fedvutrCGm3R",
        "outputId": "dd018f86-8534-4f7f-c463-fc72ba249023"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3, 3, 3, 8)\n",
            "(8,)\n",
            "(3, 3, 8, 16)\n",
            "(16,)\n",
            "(3, 3, 16, 32)\n",
            "(32,)\n",
            "(3, 3, 32, 32)\n",
            "(32,)\n",
            "(7200, 32)\n",
            "(32,)\n",
            "(32, 2)\n",
            "(2,)\n"
          ]
        }
      ],
      "source": [
        "weights=model.get_weights()#return a numpy list of weights\n",
        "for i in range(12):\n",
        "  print(weights[i].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0K-ItaV2pg-V"
      },
      "source": [
        "Path to the checkpoint repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6PJnMEMv7y4"
      },
      "outputs": [],
      "source": [
        "checkpoint_path = \"drive/MyDrive/test_archi_IA/checkpoints_airbus_new/weights.12-0.8841.cpkt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gy21gC4xqvjG"
      },
      "source": [
        "If you have a valid checkpoint you can load it here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5Kz9gTC1QIM",
        "outputId": "9f4e1d8c-5666-4515-b767-306b47e7acea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7ff19602f110>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.load_weights(checkpoint_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJIclq6H6_Ov"
      },
      "source": [
        "Use algorithm optimization to increase training speed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zbloxoCAY4E"
      },
      "outputs": [],
      "source": [
        "assert(tf.test.gpu_device_name())\n",
        "tf.keras.backend.clear_session()\n",
        "tf.config.optimizer.set_jit(True) # Enable XLA."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fp-8QJsPqy4z"
      },
      "source": [
        "Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCWMT6YS28nM"
      },
      "outputs": [],
      "source": [
        "base_learning_rate = 0.00001\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy (from_logits=False),\n",
        "              metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqps1Sb4q7FK"
      },
      "source": [
        "First batch of training.  \n",
        "Checkpoints are saved automatically when validation accuracy increase over the threshold."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58NrWrTn3RW0",
        "outputId": "7971b66e-1e85-4d35-9c2a-4022b5ed40cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "3003/3003 [==============================] - ETA: 0s - loss: 0.3640 - accuracy: 0.8440\n",
            "Epoch 1: val_accuracy improved from 0.84090 to 0.84314, saving model to drive/MyDrive/test_archi_IA/checkpoints_airbus_new/weights.01-0.8431.cpkt\n",
            "3003/3003 [==============================] - 6128s 2s/step - loss: 0.3640 - accuracy: 0.8440 - val_loss: 0.3773 - val_accuracy: 0.8431\n",
            "Epoch 2/5\n",
            "3003/3003 [==============================] - ETA: 0s - loss: 0.3618 - accuracy: 0.8461\n",
            "Epoch 2: val_accuracy did not improve from 0.84314\n",
            "3003/3003 [==============================] - 164s 54ms/step - loss: 0.3618 - accuracy: 0.8461 - val_loss: 0.3762 - val_accuracy: 0.8427\n",
            "Epoch 3/5\n",
            "3000/3003 [============================>.] - ETA: 0s - loss: 0.3599 - accuracy: 0.8469\n",
            "Epoch 3: val_accuracy improved from 0.84314 to 0.84487, saving model to drive/MyDrive/test_archi_IA/checkpoints_airbus_new/weights.03-0.8449.cpkt\n",
            "3003/3003 [==============================] - 159s 53ms/step - loss: 0.3598 - accuracy: 0.8469 - val_loss: 0.3718 - val_accuracy: 0.8449\n",
            "Epoch 4/5\n",
            "3003/3003 [==============================] - ETA: 0s - loss: 0.3583 - accuracy: 0.8471\n",
            "Epoch 4: val_accuracy improved from 0.84487 to 0.84600, saving model to drive/MyDrive/test_archi_IA/checkpoints_airbus_new/weights.04-0.8460.cpkt\n",
            "3003/3003 [==============================] - 161s 54ms/step - loss: 0.3583 - accuracy: 0.8471 - val_loss: 0.3682 - val_accuracy: 0.8460\n",
            "Epoch 5/5\n",
            "2999/3003 [============================>.] - ETA: 0s - loss: 0.3562 - accuracy: 0.8482\n",
            "Epoch 5: val_accuracy improved from 0.84600 to 0.84707, saving model to drive/MyDrive/test_archi_IA/checkpoints_airbus_new/weights.05-0.8471.cpkt\n",
            "3003/3003 [==============================] - 161s 53ms/step - loss: 0.3562 - accuracy: 0.8482 - val_loss: 0.3664 - val_accuracy: 0.8471\n"
          ]
        }
      ],
      "source": [
        "initial_epochs = 5\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=\"drive/MyDrive/test_archi_IA/checkpoints_airbus_new/weights.{epoch:02d}-{val_accuracy:.4f}.cpkt\",\n",
        "                                                 save_weights_only=True,\n",
        "                                                 monitor='val_accuracy',\n",
        "                                                 save_best_only=True,\n",
        "                                                 mode='max',\n",
        "                                                 initial_value_threshold = 0.8741,\n",
        "                                                 verbose=1)\n",
        "history = model.fit(train_dataset,\n",
        "                    epochs=initial_epochs,\n",
        "                    validation_data=validation_dataset,\n",
        "                    callbacks=cp_callback\n",
        "                    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amW7CKcG7flX"
      },
      "source": [
        "Next batch of training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzPFrnvh8I7E",
        "outputId": "7ed7f323-8866-4ee5-fc15-162329b16813"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "3000/3003 [============================>.] - ETA: 0s - loss: 0.2759 - accuracy: 0.8861\n",
            "Epoch 1: val_accuracy did not improve from 0.87757\n",
            "3003/3003 [==============================] - 162s 54ms/step - loss: 0.2758 - accuracy: 0.8861 - val_loss: 0.3029 - val_accuracy: 0.8741\n",
            "Epoch 2/20\n",
            "3003/3003 [==============================] - ETA: 0s - loss: 0.2741 - accuracy: 0.8873\n",
            "Epoch 2: val_accuracy improved from 0.87757 to 0.87917, saving model to drive/MyDrive/test_archi_IA/checkpoints_airbus_new/weights.02-0.8792.cpkt\n",
            "3003/3003 [==============================] - 164s 54ms/step - loss: 0.2741 - accuracy: 0.8873 - val_loss: 0.2949 - val_accuracy: 0.8792\n",
            "Epoch 3/20\n",
            "3003/3003 [==============================] - ETA: 0s - loss: 0.2717 - accuracy: 0.8882\n",
            "Epoch 3: val_accuracy did not improve from 0.87917\n",
            "3003/3003 [==============================] - 161s 54ms/step - loss: 0.2717 - accuracy: 0.8882 - val_loss: 0.2982 - val_accuracy: 0.8782\n",
            "Epoch 4/20\n",
            "3000/3003 [============================>.] - ETA: 0s - loss: 0.2707 - accuracy: 0.8883\n",
            "Epoch 4: val_accuracy improved from 0.87917 to 0.87924, saving model to drive/MyDrive/test_archi_IA/checkpoints_airbus_new/weights.04-0.8792.cpkt\n",
            "3003/3003 [==============================] - 161s 54ms/step - loss: 0.2707 - accuracy: 0.8882 - val_loss: 0.2939 - val_accuracy: 0.8792\n",
            "Epoch 5/20\n",
            "3003/3003 [==============================] - ETA: 0s - loss: 0.2685 - accuracy: 0.8889\n",
            "Epoch 5: val_accuracy improved from 0.87924 to 0.87997, saving model to drive/MyDrive/test_archi_IA/checkpoints_airbus_new/weights.05-0.8800.cpkt\n",
            "3003/3003 [==============================] - 163s 54ms/step - loss: 0.2685 - accuracy: 0.8889 - val_loss: 0.2901 - val_accuracy: 0.8800\n",
            "Epoch 6/20\n",
            "3000/3003 [============================>.] - ETA: 0s - loss: 0.2671 - accuracy: 0.8903\n",
            "Epoch 6: val_accuracy improved from 0.87997 to 0.88037, saving model to drive/MyDrive/test_archi_IA/checkpoints_airbus_new/weights.06-0.8804.cpkt\n",
            "3003/3003 [==============================] - 163s 54ms/step - loss: 0.2671 - accuracy: 0.8903 - val_loss: 0.2886 - val_accuracy: 0.8804\n",
            "Epoch 7/20\n",
            "2999/3003 [============================>.] - ETA: 0s - loss: 0.2657 - accuracy: 0.8908\n",
            "Epoch 7: val_accuracy improved from 0.88037 to 0.88190, saving model to drive/MyDrive/test_archi_IA/checkpoints_airbus_new/weights.07-0.8819.cpkt\n",
            "3003/3003 [==============================] - 162s 54ms/step - loss: 0.2657 - accuracy: 0.8908 - val_loss: 0.2888 - val_accuracy: 0.8819\n",
            "Epoch 8/20\n",
            "3001/3003 [============================>.] - ETA: 0s - loss: 0.2642 - accuracy: 0.8920\n",
            "Epoch 8: val_accuracy did not improve from 0.88190\n",
            "3003/3003 [==============================] - 163s 54ms/step - loss: 0.2642 - accuracy: 0.8920 - val_loss: 0.2863 - val_accuracy: 0.8817\n",
            "Epoch 9/20\n",
            "2999/3003 [============================>.] - ETA: 0s - loss: 0.2629 - accuracy: 0.8934\n",
            "Epoch 9: val_accuracy improved from 0.88190 to 0.88370, saving model to drive/MyDrive/test_archi_IA/checkpoints_airbus_new/weights.09-0.8837.cpkt\n",
            "3003/3003 [==============================] - 162s 54ms/step - loss: 0.2628 - accuracy: 0.8934 - val_loss: 0.2856 - val_accuracy: 0.8837\n",
            "Epoch 10/20\n",
            "3000/3003 [============================>.] - ETA: 0s - loss: 0.2613 - accuracy: 0.8932\n",
            "Epoch 10: val_accuracy did not improve from 0.88370\n",
            "3003/3003 [==============================] - 174s 58ms/step - loss: 0.2613 - accuracy: 0.8932 - val_loss: 0.2923 - val_accuracy: 0.8828\n",
            "Epoch 11/20\n",
            "3001/3003 [============================>.] - ETA: 0s - loss: 0.2597 - accuracy: 0.8943\n",
            "Epoch 11: val_accuracy did not improve from 0.88370\n",
            "3003/3003 [==============================] - 161s 54ms/step - loss: 0.2597 - accuracy: 0.8942 - val_loss: 0.2843 - val_accuracy: 0.8836\n",
            "Epoch 12/20\n",
            "3001/3003 [============================>.] - ETA: 0s - loss: 0.2581 - accuracy: 0.8950\n",
            "Epoch 12: val_accuracy improved from 0.88370 to 0.88410, saving model to drive/MyDrive/test_archi_IA/checkpoints_airbus_new/weights.12-0.8841.cpkt\n",
            "3003/3003 [==============================] - 159s 53ms/step - loss: 0.2581 - accuracy: 0.8949 - val_loss: 0.2821 - val_accuracy: 0.8841\n",
            "Epoch 13/20\n",
            "3001/3003 [============================>.] - ETA: 0s - loss: 0.2569 - accuracy: 0.8948\n",
            "Epoch 13: val_accuracy improved from 0.88410 to 0.88483, saving model to drive/MyDrive/test_archi_IA/checkpoints_airbus_new/weights.13-0.8848.cpkt\n",
            "3003/3003 [==============================] - 159s 53ms/step - loss: 0.2569 - accuracy: 0.8949 - val_loss: 0.2838 - val_accuracy: 0.8848\n",
            "Epoch 14/20\n",
            "2999/3003 [============================>.] - ETA: 0s - loss: 0.2550 - accuracy: 0.8955\n",
            "Epoch 14: val_accuracy improved from 0.88483 to 0.88610, saving model to drive/MyDrive/test_archi_IA/checkpoints_airbus_new/weights.14-0.8861.cpkt\n",
            "3003/3003 [==============================] - 159s 53ms/step - loss: 0.2551 - accuracy: 0.8954 - val_loss: 0.2804 - val_accuracy: 0.8861\n",
            "Epoch 15/20\n",
            "3000/3003 [============================>.] - ETA: 0s - loss: 0.2540 - accuracy: 0.8961\n",
            "Epoch 15: val_accuracy did not improve from 0.88610\n",
            "3003/3003 [==============================] - 158s 53ms/step - loss: 0.2540 - accuracy: 0.8961 - val_loss: 0.2859 - val_accuracy: 0.8846\n",
            "Epoch 16/20\n",
            "3003/3003 [==============================] - ETA: 0s - loss: 0.2526 - accuracy: 0.8975\n",
            "Epoch 16: val_accuracy improved from 0.88610 to 0.88637, saving model to drive/MyDrive/test_archi_IA/checkpoints_airbus_new/weights.16-0.8864.cpkt\n",
            "3003/3003 [==============================] - 157s 52ms/step - loss: 0.2526 - accuracy: 0.8975 - val_loss: 0.2795 - val_accuracy: 0.8864\n",
            "Epoch 17/20\n",
            "2999/3003 [============================>.] - ETA: 0s - loss: 0.2510 - accuracy: 0.8983\n",
            "Epoch 17: val_accuracy improved from 0.88637 to 0.88756, saving model to drive/MyDrive/test_archi_IA/checkpoints_airbus_new/weights.17-0.8876.cpkt\n",
            "3003/3003 [==============================] - 158s 53ms/step - loss: 0.2510 - accuracy: 0.8983 - val_loss: 0.2786 - val_accuracy: 0.8876\n",
            "Epoch 18/20\n",
            "3000/3003 [============================>.] - ETA: 0s - loss: 0.2497 - accuracy: 0.8987\n",
            "Epoch 18: val_accuracy did not improve from 0.88756\n",
            "3003/3003 [==============================] - 158s 52ms/step - loss: 0.2498 - accuracy: 0.8987 - val_loss: 0.2794 - val_accuracy: 0.8872\n",
            "Epoch 19/20\n",
            "3000/3003 [============================>.] - ETA: 0s - loss: 0.2482 - accuracy: 0.8994\n",
            "Epoch 19: val_accuracy improved from 0.88756 to 0.88843, saving model to drive/MyDrive/test_archi_IA/checkpoints_airbus_new/weights.19-0.8884.cpkt\n",
            "3003/3003 [==============================] - 161s 53ms/step - loss: 0.2482 - accuracy: 0.8994 - val_loss: 0.2754 - val_accuracy: 0.8884\n",
            "Epoch 20/20\n",
            "3001/3003 [============================>.] - ETA: 0s - loss: 0.2472 - accuracy: 0.9007\n",
            "Epoch 20: val_accuracy did not improve from 0.88843\n",
            "3003/3003 [==============================] - 163s 54ms/step - loss: 0.2471 - accuracy: 0.9007 - val_loss: 0.2739 - val_accuracy: 0.8882\n"
          ]
        }
      ],
      "source": [
        "initial_epochs = 20\n",
        "\n",
        "history = model.fit(train_dataset,\n",
        "                    epochs=initial_epochs,\n",
        "                    validation_data=validation_dataset,\n",
        "                    callbacks=cp_callback\n",
        "                    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnSVvMo0rcRc"
      },
      "source": [
        "Evaluate the model on test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNbaZ72dtr1t",
        "outputId": "fb08209e-5bc5-4afd-989e-70ebd1cb84fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 1s 83ms/step - loss: 0.8433 - accuracy: 0.8347\n",
            "accuracy: 83.47%\n"
          ]
        }
      ],
      "source": [
        "scores = model.evaluate(test_dataset, verbose=1)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHSpiBImrg57"
      },
      "source": [
        "Here you can visualize the model predictions on a batch of images from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gqCAKuslU10"
      },
      "outputs": [],
      "source": [
        "# Retrieve a batch of images from the test set\n",
        "image_batch, label_batch = test_dataset.as_numpy_iterator().next()\n",
        "predictions = model.predict_on_batch(image_batch)\n",
        "print(predictions)\n",
        "predictions = model.predict_on_batch(image_batch).flatten()\n",
        "n = 0\n",
        "results = {}\n",
        "for i in range(0,10) :\n",
        "  if  (max(predictions[n], predictions[n+1]) == predictions[n]) :\n",
        "    results[i] = 0\n",
        "  if (max(predictions[n], predictions[n+1]) == predictions[n+1]) :\n",
        "    results[i] = 1\n",
        "  n += 2 \n",
        "print(results)\n",
        "\n",
        "print('Predictions:\\n', results)\n",
        "print('Labels:\\n', label_batch)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "  ax = plt.subplot(3, 3, i + 1)\n",
        "  plt.imshow(image_batch[i].astype(\"uint8\"))\n",
        "  plt.title(class_names[results[i]])\n",
        "  plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wW4HeZX4sJ-v"
      },
      "source": [
        "Fine tuning on the model .To be done when accuracy reach celling on classic training (usually around 95%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhMvpFwPlrKJ"
      },
      "outputs": [],
      "source": [
        "model.trainable = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrffzVwj8BeX"
      },
      "source": [
        "Choose how many layer you want to freeze"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrwqhxE7lrwy",
        "outputId": "14653eee-d70a-43cd-f5e4-ada5aef6e978"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of layers in the base model:  13\n"
          ]
        }
      ],
      "source": [
        "# Let's take a look to see how many layers are in the base model\n",
        "print(\"Number of layers in the base model: \", len(model.layers))\n",
        "\n",
        "# Fine-tune from this layer onwards\n",
        "fine_tune_at = 9\n",
        "\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in model.layers[:fine_tune_at]:\n",
        "  layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBmXsdYQm7ZZ"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLujsjBxsXez",
        "outputId": "6a3f9e3b-5044-4eaf-8712-75d4b49ae5b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "3003/3003 [==============================] - ETA: 0s - loss: 0.1057 - accuracy: 0.9625"
          ]
        }
      ],
      "source": [
        "fine_tune_epochs = 10\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=\"drive/MyDrive/test_archi_IA/checkpoints_airbus/weights.{epoch:02d}-{val_accuracy:.4f}.cpkt\",\n",
        "                                                 save_weights_only=True,\n",
        "                                                 monitor='val_accuracy',\n",
        "                                                 save_best_only=True,\n",
        "                                                 mode='max',\n",
        "                                                 initial_value_threshold = 0.91074,\n",
        "                                                 verbose=1)\n",
        "\n",
        "history = model.fit(train_dataset,\n",
        "                    epochs=fine_tune_epochs,\n",
        "                    validation_data=validation_dataset,\n",
        "                    callbacks = cp_callback\n",
        "                    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeVO-aq-srhr"
      },
      "source": [
        "Evaluate model after fine tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aVj-I9TsrM4"
      },
      "outputs": [],
      "source": [
        "scores = model.evaluate(test_dataset, verbose=1)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "entrainement_airbus.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "16e9d84234055fed9ddc2e6506aa3a0f7fe6031d03d72aa0f2ad64cbba7fa562"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
