{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "export_weights.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook provides code to export your weights to JSON format"
      ],
      "metadata": {
        "id": "mAOsK49-8lkh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAy9CCqdxE1Z",
        "outputId": "7a66eed4-083a-4da1-9121-ec411e27e030"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "# This mounts your Google Drive to the Colab VM.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "\n",
        "# Enter the foldername in your Drive where you have saved the unzipped\n",
        "# assignment folder, e.g. 'cs231n/assignments/assignment1/'\n",
        "FOLDERNAME = 'transfer_learning_mobilenet'\n",
        "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
        "\n",
        "# Now that we've mounted your Drive, this ensures that\n",
        "# the Python interpreter of the Colab VM can load\n",
        "# python files from within it.\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "NOph-GE-8sKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "from time import time\n",
        "import math\n",
        "import json\n",
        "import os\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D, DepthwiseConv2D, ReLU, BatchNormalization, add,Softmax, AveragePooling2D, Dense, Input, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from mobilenetv2 import*"
      ],
      "metadata": {
        "id": "mvDpO7g7yRCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the model and save the arch to be written in JSON file"
      ],
      "metadata": {
        "id": "UbWfu0xg8wtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list_arch = []\n",
        "rescale = tf.keras.layers.Rescaling(1./127.5, offset=-1)\n",
        "\n",
        "inputs = tf.keras.Input(shape=(240, 240, 3))\n",
        "network = rescale(inputs)\n",
        "list_arch.append(\"57600\")\n",
        "\n",
        "network = tf.keras.layers.Conv2D(4, (3,3), padding='same', activation='relu')(network)\n",
        "list_arch.append(\"C3:4:1\")\n",
        "network = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(network)\n",
        "list_arch.append(\"P2\")\n",
        "\n",
        "network = tf.keras.layers.Conv2D(8, (3,3), padding='same', activation='relu')(network)\n",
        "list_arch.append(\"C3:8:1\")\n",
        "network = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(network)\n",
        "list_arch.append(\"P2\")\n",
        "\n",
        "network = tf.keras.layers.Conv2D(32, (3,3), padding='same', activation='relu')(network)\n",
        "list_arch.append(\"C3:32:1\")\n",
        "network = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(network)\n",
        "list_arch.append(\"P2\")\n",
        "\n",
        "network = tf.keras.layers.Conv2D(32, (3,3), padding='same', activation='relu')(network)\n",
        "list_arch.append(\"C3:32:1\")\n",
        "network = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(network)\n",
        "list_arch.append(\"P2\")\n",
        "\n",
        "network = tf.keras.layers.Flatten()(network)\n",
        "network = tf.keras.layers.Dense(32, activation='relu')(network)\n",
        "list_arch.append(\"32\")\n",
        "outputs = tf.keras.layers.Dense(2, activation='softmax')(network)\n",
        "list_arch.append(\"2\")\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model.summary()\n",
        "print(list_arch)\n",
        "print(len(list_arch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Nh9T_yP0fQN",
        "outputId": "91f0e4b0-72d9-4559-a0d0-6ff95708065f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 240, 240, 3)]     0         \n",
            "                                                                 \n",
            " rescaling_1 (Rescaling)     (None, 240, 240, 3)       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 240, 240, 4)       112       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 120, 120, 4)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 120, 120, 8)       296       \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 60, 60, 8)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 60, 60, 32)        2336      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 30, 30, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 30, 30, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 15, 15, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 7200)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                230432    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 242,490\n",
            "Trainable params: 242,490\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "['57600', 'C3:4:1', 'P2', 'C3:8:1', 'P2', 'C3:32:1', 'P2', 'C3:32:1', 'P2', '32', '2']\n",
            "11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load checkpoint corresponding to the model which you want to save"
      ],
      "metadata": {
        "id": "trlhATm585Wv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"drive/MyDrive/test_archi_IA/checkpoints_airbus_wo_rscl/weights_low_krn.04-0.8714.cpkt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "model.load_weights(checkpoint_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYUIFJRpyRqZ",
        "outputId": "8e2d4b03-5a9e-47dc-fcb4-86ed6528c6ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.layers.convolutional.Conv2D object at 0x7f50fd263390> and <keras.layers.preprocessing.image_preprocessing.Rescaling object at 0x7f50f9d9fb90>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.layers.convolutional.Conv2D object at 0x7f50f9d47810> and <keras.layers.pooling.MaxPooling2D object at 0x7f50f9d98b50>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.layers.convolutional.Conv2D object at 0x7f50f9cea510> and <keras.layers.pooling.MaxPooling2D object at 0x7f50f9ce5090>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.layers.convolutional.Conv2D object at 0x7f50f9d47f90> and <keras.layers.pooling.MaxPooling2D object at 0x7f50f9cf0dd0>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.layers.core.dense.Dense object at 0x7f50f9d9ffd0> and <keras.layers.core.flatten.Flatten object at 0x7f50f9cf7a10>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.layers.core.dense.Dense object at 0x7f50f9d41090> and <keras.layers.core.dense.Dense object at 0x7f50f9d9ffd0>).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f518766ab50>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Writes weights to JSON format "
      ],
      "metadata": {
        "id": "GP6MXw2o9Abv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "weights=model.get_weights()#return a numpy list of weights\n",
        "for i in range(0,len(weights)):\n",
        "  print(weights[i].shape)\n",
        "class NumpyEncoder(json.JSONEncoder):\n",
        "    def default(self, obj):\n",
        "        if isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        return json.JSONEncoder.default(self, obj)\n",
        "json_dump = \"\"\n",
        "json_1 = json.dumps({\"size\" : len(list_arch)})\n",
        "json_2 = json.dumps({\"arch\" : list_arch})\n",
        "for i in range(0,len(weights)) :\n",
        "  json_temp = json.dumps({\"layer{}\".format(i) : weights[i]}, cls=NumpyEncoder)\n",
        "  json_dump = json_dump+json_temp\n",
        "json_3 = json.dumps({\"weights\" : json_dump})\n",
        "json_dump = json_1 + json_2 + json_3\n",
        "\n",
        "with open('./drive/MyDrive/test_archi_IA/weights_airbus_4krn.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(json_dump, f, ensure_ascii=False, indent=4)\n",
        "print(\"saved in file\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEjco0Uay_vZ",
        "outputId": "35717316-fcd0-4235-e690-3fbe3ac3fdc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 3, 3, 4)\n",
            "(4,)\n",
            "(3, 3, 4, 8)\n",
            "(8,)\n",
            "(3, 3, 8, 32)\n",
            "(32,)\n",
            "(3, 3, 32, 32)\n",
            "(32,)\n",
            "(7200, 32)\n",
            "(32,)\n",
            "(32, 2)\n",
            "(2,)\n",
            "saved in file\n"
          ]
        }
      ]
    }
  ]
}